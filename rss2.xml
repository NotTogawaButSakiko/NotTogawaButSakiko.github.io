<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Sakiko&#39;s Blog</title>
    <link>http://nottogawabutsakiko.github.io/</link>
    
    <atom:link href="http://nottogawabutsakiko.github.io/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>弱い私はもう死にました。</description>
    <pubDate>Sun, 29 Sep 2024 08:21:39 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>复杂度</title>
      <link>http://nottogawabutsakiko.github.io/%E7%AC%94%E8%AE%B0/calculation%20therom%20base/</link>
      <guid>http://nottogawabutsakiko.github.io/%E7%AC%94%E8%AE%B0/calculation%20therom%20base/</guid>
      <pubDate>Sun, 29 Sep 2024 08:21:39 GMT</pubDate>
      
      <description>&lt;p&gt;在之前的博文中, 我们研究了时间复杂度, 这可以有效的帮助我们大体评析和优化算法。然而，不管我们多么尽力的优化算法，有些问题是极其 “难” 的，使得我们不能在很短的时间内解决。&lt;/p&gt;
&lt;p&gt;本文讲述的 $NP$ 类问题正是用来帮助我们评析一个 &lt;strong&gt;问题&lt;/strong&gt; 的复杂程度。注意的是本文并不形式化，即不引入语言体系。以及本文一切证明也非形式化。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>在之前的博文中, 我们研究了时间复杂度, 这可以有效的帮助我们大体评析和优化算法。然而，不管我们多么尽力的优化算法，有些问题是极其 “难” 的，使得我们不能在很短的时间内解决。</p><p>本文讲述的 $NP$ 类问题正是用来帮助我们评析一个 <strong>问题</strong> 的复杂程度。注意的是本文并不形式化，即不引入语言体系。以及本文一切证明也非形式化。</p><span id="more"></span><h1 id="判定问题与最优化问题"><a href="#判定问题与最优化问题" class="headerlink" title="判定问题与最优化问题"></a>判定问题与最优化问题</h1><p><strong>判定问题</strong> (decision problem) 指的是答案只有 “是” 或 “否” 的问题</p><p><strong>最优化问题</strong> (optimization problem) 其中每一个解有一个关联的值, 我们希望找出一个具有最佳值的可行解。如最短路问题就是一个最优化问题</p><p>在后面的 $NP-C$ 类问题中所描述的其实都是判定问题, 但是最优化问题是可以转化为多个判定问题。而判定问题相对于最优化问题来说，”难度” 一定是小于等于后者的。所以我们对于判定问题的讨论是可以帮助我们评价一个最优化问题的复杂度的。</p><h1 id="规约"><a href="#规约" class="headerlink" title="规约"></a>规约</h1><p>事实上，我们很难证明一个问题他到底 “难不难” , 因为人们到目前为止都没有证明出 $P$ 是否等于 $NP$ (后文会阐述)。</p><p>但是，问题的相对难度比较却是很容易的。我们可以通过一个已知难度的问题，通过比较来确定新问题的难度。这种比较就是 <strong>规约</strong> (reduction)</p><p>我们已知一个判定问题 $B$ , 和一个已知难度的判定问题 $A$ . 我们称一个问题的输入为 <strong>实例</strong> (instance) 。问题 $A$ 的实例为 $\alpha$ , 问题 $B$ 的实例为 $\beta$ , 如果任何实例 $\alpha$ 都可以转化成满足以下条件的实例 $\beta$ :</p><ul><li>转换操作在多项式时间之内</li><li>两个实例的解是相同的. 即若 $\alpha$ 的解是 “是”，则 $\beta$ 的解也应当是 “是”</li></ul><p>则我们称 $A$ 可以规约到 $B$ ,即 $B$ 的难度至少和 $A$ “一样难”。</p><p>例如一元一次方程可以规约到二元一次方程，则二元一次方程的难度大于等于前者。</p><h1 id="NP-类问题-nondeterministic-polynomial-time"><a href="#NP-类问题-nondeterministic-polynomial-time" class="headerlink" title="$NP$ 类问题 (nondeterministic polynomial time)"></a>$NP$ 类问题 (nondeterministic polynomial time)</h1><h2 id="P-类问题"><a href="#P-类问题" class="headerlink" title="$P$ 类问题"></a>$P$ 类问题</h2><p>$P$ 类问题指的是可以在多项式时间内找到解的问题。这类问题是最简单的问题，我们绝大部分解决的问题都是 $P$ 类问题。</p><h2 id="NP-类问题"><a href="#NP-类问题" class="headerlink" title="$NP$ 类问题"></a>$NP$ 类问题</h2><p>$NP$ 类问题指的是可以在多项式时间内验证一个答案的正确性。正如填数独是一个很困难的问题，然而去验证一个填好的数独是否正确却很简单。</p><p>显然，所有 $P$ 问题都是 $NP$ 类问题，那么，是否 $NP$ 问题也一定是 $P$ 问题呢？</p><p>我不知道。事实上，目前世界上还没有人知道。这个被誉为千禧年七大数学未解之谜之一的难题已经困扰了人们半个世纪，即 $P ≟ NP$</p><p>于是数学家想出了一个方法，我们把所有 $NP$ 类问题都规约到某一些问题，即某一些问题的难度不低于任何 $NP$ 类问题. 只要我们证明了这一些问题中的一个问题是 $P$ 类问题，我们就能证明所有 $NP$ 类问题都是 $P$ 类问题, 即 $P &#x3D; NP$.</p><p>这一些问题即为 $NP-Complete$ 问题, 也叫 $NP-C$ 问题。</p><h2 id="NP-C-类问题"><a href="#NP-C-类问题" class="headerlink" title="$NP-C$ 类问题"></a>$NP-C$ 类问题</h2><p>由上文可以看出，$NP-C$ 问题是最难的一类问题。如果一个问题是 $NP$ 类问题，且所有 $NP$ 类问题都可以规约到这个问题，则这个问题即为 $NP-C$ 类问题。</p><p>许多著名的问题都是 $NP-C$ 类问题，例如蛋白质的折叠和金融加密等等。遗憾的是，目前还没有一个 $NP-C$ 类问题得到解决。只要证明 $P &#x3D; NP$ , 人类文明将会得到突破性的飞跃。世界不再有癌症，一切密码都是无效的，任何人都可以成为莫扎特和高斯。。。</p><h3 id="第一个-NP-C-问题"><a href="#第一个-NP-C-问题" class="headerlink" title="第一个 $NP-C$ 问题"></a>第一个 $NP-C$ 问题</h3><p>我们知道，要证明一个 $NP-C$ 问题，首先要证明一个已知的 $NP-C$ 能规约到这个问题上。因此，我们必须已知一个 $NP-C$ 问题。这个问题即 <strong>电路可满足性问题</strong></p><p><strong>电路可满足性问题</strong> : 给定一个由 $AND$ , $OR$ 和 $NOT$ 组成的 <strong>布尔组合电路</strong> ，它是 <strong>可满足</strong> 电路 吗？</p><p><strong>布尔组合电路</strong> : 由一个或多个 <strong>布尔组合元素</strong> (<strong>逻辑门</strong>) 通过线路连接而成。需要注意布尔组合电路不包含回路。</p><p><strong>可满足</strong> : 如果一个单输出布尔组合电路具有一个可满足性赋值 (即使得电路的输出为 $1$ 的一个真值赋值), 就称该布尔组合电路是可满足的。</p><p>证明略。</p><h3 id="证明-NP-C-问题"><a href="#证明-NP-C-问题" class="headerlink" title="证明 $NP-C$ 问题"></a>证明 $NP-C$ 问题</h3><p>证明一个题无解或者证明一个题不能在多项式时间内完成都是极其困难的，然而证明 $NP-C$ 问题却相对简单:</p><ol><li>证明该问题为 $NP$ 问题</li><li>证明一个已知的 $NP-C$ 问题可以归约到该问题上</li></ol><h3 id="史上第一个被证明的-NP-C-问题"><a href="#史上第一个被证明的-NP-C-问题" class="headerlink" title="史上第一个被证明的 $NP-C$ 问题"></a>史上第一个被证明的 $NP-C$ 问题</h3><p>$SAT$ (布尔公式可满足性) 是史上第一个被证明的 $NP-C$ 问题。</p><ol><li>证明 $SAT$ 问题是 $NP$ 问题</li></ol><p>易得 $SAT$ 的一个解的证书可以在线性时间能得到验证。所以 $SAT$ 为 $NP$ 问题</p><ol start="2"><li>证明电路可满足性问题可以规约到 $SAT$ 问题</li></ol><p>易得电路可满足性问题是只有与、或、非的布尔公式。所以电路可满足性问题可以规约到 $SAT$ 问题</p><p>综上, $SAT$ 问题是 $NP-C$ 问题</p><h3 id="k-CNF-问题"><a href="#k-CNF-问题" class="headerlink" title="$k-CNF$ 问题"></a>$k-CNF$ 问题</h3><p>若布尔公式是由 $AND$ 连接若干 $OR$ 字句，且每个子句中恰有 $k$ 个布尔变量或其否定形式，问其是否可满足。</p><p>例如 $(x_1 \lor x_2) \land (\urcorner x_1 \lor x_3) \land (\urcorner x_2 \lor x_3)$ 就是一个 $2-CNF$ 问题</p><p>可以确定 $2-CNF$ 是一个 $P$ 类问题, 但是 $3-CNF$ 可以被证明为 $NP-C$ 问题</p><p>证明略</p><h3 id="哈密顿回路和旅行商问题"><a href="#哈密顿回路和旅行商问题" class="headerlink" title="哈密顿回路和旅行商问题"></a>哈密顿回路和旅行商问题</h3><p>无向图 $G(V,E)$ 中的一条 <strong>哈密顿回路</strong> 是通过 $V$ 中的每个顶点的简单回路。具有这种回路的图被称为 <strong>哈密顿图</strong> .</p><p>可以知道验证一个图是否为哈密顿图需要 $O(n!)$ 的时间复杂度, 且在 $O(n^2)$ 时间内验证验证一个回路是否为哈密顿回路。所以显然哈密顿回路问题是一个 $NP$ 问题。</p><p>而 $NP-C$ 顶点覆盖问题可以规约到哈密顿回路问题上，所以哈密顿回路问题是一个 $NP-C$ 问题。</p><img data-src="/images/Hamiltonian_path.png" style="display: block; margin: auto; height: 250px" alt="哈密顿回路"/><p>在旅行商问题中，一个售货员必须访问一个完全图中所有顶点且回到最初顶点，花费的费用是边权之和，求最小费用。</p><p>易知旅行商问题也是一个哈密顿回路，所以哈密顿回路可以规约到旅行商问题上。而旅行商问题显然是 $NP$ 问题，所以旅行商问题也是 $NP-C$ 问题。</p><h2 id="NP-Hard-问题"><a href="#NP-Hard-问题" class="headerlink" title="$NP-Hard$ 问题"></a>$NP-Hard$ 问题</h2><p>所有 $NP$ 问题都可以规约到该类问题，且该类问题不一定是 $NP$ 问题，即可能无法在多项式时间内验证一个解的证书的正确性。</p><p>该类问题为最难的一类问题。</p><img data-src="/images/P_np_np-complete_np-hard.png" style="background-color: #515151" alt="P ≟ NP"/>]]></content:encoded>
      
      
      <category domain="http://nottogawabutsakiko.github.io/categories/%E7%AC%94%E8%AE%B0/">笔记</category>
      
      
      <category domain="http://nottogawabutsakiko.github.io/tags/%E7%AE%97%E6%B3%95/">算法</category>
      
      
      <comments>http://nottogawabutsakiko.github.io/%E7%AC%94%E8%AE%B0/calculation%20therom%20base/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>前缀和与差分</title>
      <link>http://nottogawabutsakiko.github.io/%E7%AC%94%E8%AE%B0/basic%20linear%20otimize%20algorithms/</link>
      <guid>http://nottogawabutsakiko.github.io/%E7%AC%94%E8%AE%B0/basic%20linear%20otimize%20algorithms/</guid>
      <pubDate>Fri, 27 Sep 2024 04:38:16 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;前缀和&quot;&gt;&lt;a href=&quot;#前缀和&quot; class=&quot;headerlink&quot; title=&quot;前缀和&quot;&gt;&lt;/a&gt;前缀和&lt;/h1&gt;&lt;p&gt;给定一个数组，我们需要进行多次查询区间和，如何每次查询在 $O(1)$ 时间内呢？&lt;/p&gt;
&lt;p&gt;我们令 $sum_i$ 为前 $i$ 个数的和，若想得到区间 $l, r$ 的区间和，我们只需求 $sum_r - sum_{l - 1}$ 即可。&lt;/p&gt;
&lt;p&gt;我们将该算法称为前缀和。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h1 id="前缀和"><a href="#前缀和" class="headerlink" title="前缀和"></a>前缀和</h1><p>给定一个数组，我们需要进行多次查询区间和，如何每次查询在 $O(1)$ 时间内呢？</p><p>我们令 $sum_i$ 为前 $i$ 个数的和，若想得到区间 $l, r$ 的区间和，我们只需求 $sum_r - sum_{l - 1}$ 即可。</p><p>我们将该算法称为前缀和。</p><span id="more"></span><h2 id="前缀和的推广"><a href="#前缀和的推广" class="headerlink" title="前缀和的推广"></a>前缀和的推广</h2><p>我们现在不查询区间和，而是查询区间积，如何操作呢？</p><p>我们不难想到只需维护用 $mul_i$ 表示前 $i$ 个数的积，若查询区间 $[l,r]$ 的区间积，我们只需找到 $mul_r &#x2F; mul_{l - 1}$ .</p><p>然而现在我们需要对一个数组的数据进行多次查询区间最大值，还能如此操作吗？</p><p>我们发现前缀和方法失效了，因为我们无法找到最大值操作的 <strong>逆操作</strong> ，即使我们维护了前 $i$ 个数的最大值，我们也无法抵消前 $l-1$ 个数的影响。</p><p>我们还发现，除法、或操作也是无法进行前缀和，但是异或操作确可以。</p><p>进一步说，当运算在数据中符合 <strong>封闭性、结合律</strong> ，存在 <strong>单位元、逆元</strong> ，才能使用前缀和。</p><p>也就是说对于数组 $A$ ，$A$ 关于该运算构成 <strong>群</strong> ，则该运算可使用前缀和。</p><h2 id="二维前缀和"><a href="#二维前缀和" class="headerlink" title="二维前缀和"></a>二维前缀和</h2><p>我们将上述的数组扩展到二维，多次进行二维区间查询和，满足 $O(1)$ 查询。</p><p>考虑容斥原理，设 $sum_{i,j}$ 是前 $i$ 行 $j$ 列的和, 对于二维区间 $[(l_i, l_j), (r_i, r_j)]$ , 只需查询 $sum_{r_i,r_j} - sum_{l_i-1,r_j} - sum_{r_i, l_j-1} + sum_{l_i-1,l_j-1}$ </p><h2 id="高维前缀和-SOSDP"><a href="#高维前缀和-SOSDP" class="headerlink" title="高维前缀和(SOSDP)"></a>高维前缀和(SOSDP)</h2><p>我们计算 $k$ 维的前缀和，若依然用容斥的算法去做，那么复杂度是 $O(2^kn^k)$ , 是我们难以接受的。</p><p>考虑如何不使用容斥来降低复杂度。</p><p>回到二维前缀和, 我们将算法变为如下伪代码:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">for i from 1 to n</span><br><span class="line">    for j from 1 to n</span><br><span class="line">        a[i][j] += a[i][j - 1]</span><br><span class="line"></span><br><span class="line">for i from 1 to n</span><br><span class="line">    for j from 1 to n</span><br><span class="line">        a[i][j] += a[i - 1][j]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其中 $a_{i,j}$ 为原数组。</p><p>我们发现这样行和列是互不干扰的。复杂度为 $O(kn^k)$ , 在维度大于 $2$ 的时候复杂度优于容斥算法。</p><p>推广到 $n$ 维，我们将其状态压缩成 $state$, 枚举每 $i$ 维，对于原数组 $a_{state}$ , 从 $a_{state_{i-1}}$ 转移过来。</p><p>例题：<span class="exturl" data-url="aHR0cHM6Ly9hdGNvZGVyLmpwL2NvbnRlc3RzL2FyYzEwMC90YXNrcy9hcmMxMDBfYw==">OR PLUS MAX<i class="fa fa-external-link-alt"></i></span></p><h2 id="树上前缀和"><a href="#树上前缀和" class="headerlink" title="树上前缀和"></a>树上前缀和</h2><p>记 $sum_i$ 为 $i$ 节点到根节点的权值总和。</p><ul><li><p>若为点权总和，则 $s, t$ 路径上权值总和为 $sum_s + sum_t - sum_{lca} - sum_{fa_{lca}}$</p></li><li><p>若为边权总和，则 $s, t$ 路径上权值总和为 $sum_s + sum_t - 2sum_{lca}$</p></li></ul><h1 id="差分"><a href="#差分" class="headerlink" title="差分"></a>差分</h1><p>给定一个数组，我们需要进行多次修改区间，如何每次修改在 $O(1)$ 时间内呢？</p><p>我们将 $cha_i$ 设为第 $i$ 个数与第 $i-1$ 个数的差，每次修改区间 $[l, r]$ ，我们只需修改 $cha_l, cha_{r+1}$ 即可。每次询问第 $i$ 个数求差分数组前 $i$ 个数的和即可。</p><p>我们将该算法称为差分。我们发现这种算法的修改与前缀和的查询类似，查询与前缀和的维护类似。不难发现差分即是前缀和的 <strong>逆操作</strong></p><h2 id="树上差分"><a href="#树上差分" class="headerlink" title="树上差分"></a>树上差分</h2><p>记 $cha_i$ 为 $i$ 节点与其父节点的差值。</p><ul><li><p>若为点权差分，将 $s, t$ 路径上权值加上 $k$，我们进行以下操作</p><p>  $$cha_s \leftarrow cha_s + k$$<br>  $$cha_t \leftarrow cha_t + k$$<br>  $$cha_{lca} \leftarrow cha_{lca} - k$$<br>  $$cha_{fa_{lca}} \leftarrow cha_{fa_{lca}} - k$$</p></li><li><p>若为边权差分，我们将边权下放到临近深度更大的点上存储。</p><p>  $$cha_s \leftarrow cha_s + k$$<br>  $$cha_t \leftarrow cha_t + k$$<br>  $$cha_{lca} \leftarrow cha_{lca} - 2k$$</p></li></ul>]]></content:encoded>
      
      
      <category domain="http://nottogawabutsakiko.github.io/categories/%E7%AC%94%E8%AE%B0/">笔记</category>
      
      
      <category domain="http://nottogawabutsakiko.github.io/tags/%E7%AE%97%E6%B3%95/">算法</category>
      
      
      <comments>http://nottogawabutsakiko.github.io/%E7%AC%94%E8%AE%B0/basic%20linear%20otimize%20algorithms/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>时间复杂度</title>
      <link>http://nottogawabutsakiko.github.io/%E7%AC%94%E8%AE%B0/complexity/</link>
      <guid>http://nottogawabutsakiko.github.io/%E7%AC%94%E8%AE%B0/complexity/</guid>
      <pubDate>Mon, 09 Sep 2024 14:47:38 GMT</pubDate>
      
      <description>&lt;p&gt;一个算法中的语句最坏情况下执行次数称为 &lt;strong&gt;语句频度&lt;/strong&gt; 或 &lt;strong&gt;时间频度&lt;/strong&gt; 记为 $T(n)$.&lt;/p&gt;
&lt;p&gt;然而, 当输入规模足够大, 我们便不用确定算法的精确运行次数, 只需要考虑算法的增长量级即可, 因此我们要研究算法的 &lt;strong&gt;渐进&lt;/strong&gt; 效率.&lt;/p&gt;
&lt;p&gt;若存在 $f(n)$ ,使 $&#92;lim &#92;limits_{n -&amp;gt; &#92;infty} &#92;frac{T(n)}{f(n)}$ 为不等于零的常数, 则称 $f(n)$ 为 $T(n)$ 的 &lt;strong&gt;同数量级(阶)函数&lt;/strong&gt; ,记作:&lt;/p&gt;
&lt;p&gt;$$T(n) &amp;#x3D; F(f(n))$$&lt;/p&gt;
&lt;p&gt;则称 $F(f(n))$ 为算法 $T(n)$ 的 &lt;strong&gt;渐进时间复杂度&lt;/strong&gt;, 简称 &lt;strong&gt;时间复杂度&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;这里的 $F$ , 就是 &lt;strong&gt;渐进符号&lt;/strong&gt; &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里的 $T(n) &amp;#x3D; F(f(n))$ 中的 $&amp;#x3D;$ 实际并不准确. 正常来说应当是 $T(n) ∈ F(f(n))$ , 即 $T(n)$ 是 $F(f(n))$ 的一个元素.为了方便描述, 我们约定 $T(n) &amp;#x3D; F(f(n))$ 表达相同的概念. 后文相同.&lt;/p&gt;
&lt;/blockquote&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>一个算法中的语句最坏情况下执行次数称为 <strong>语句频度</strong> 或 <strong>时间频度</strong> 记为 $T(n)$.</p><p>然而, 当输入规模足够大, 我们便不用确定算法的精确运行次数, 只需要考虑算法的增长量级即可, 因此我们要研究算法的 <strong>渐进</strong> 效率.</p><p>若存在 $f(n)$ ,使 $\lim \limits_{n -&gt; \infty} \frac{T(n)}{f(n)}$ 为不等于零的常数, 则称 $f(n)$ 为 $T(n)$ 的 <strong>同数量级(阶)函数</strong> ,记作:</p><p>$$T(n) &#x3D; F(f(n))$$</p><p>则称 $F(f(n))$ 为算法 $T(n)$ 的 <strong>渐进时间复杂度</strong>, 简称 <strong>时间复杂度</strong>.</p><p>这里的 $F$ , 就是 <strong>渐进符号</strong> </p><blockquote><p>这里的 $T(n) &#x3D; F(f(n))$ 中的 $&#x3D;$ 实际并不准确. 正常来说应当是 $T(n) ∈ F(f(n))$ , 即 $T(n)$ 是 $F(f(n))$ 的一个元素.为了方便描述, 我们约定 $T(n) &#x3D; F(f(n))$ 表达相同的概念. 后文相同.</p></blockquote><span id="more"></span><h1 id="计算同阶函数-证明略"><a href="#计算同阶函数-证明略" class="headerlink" title="计算同阶函数 (证明略)"></a>计算同阶函数 (证明略)</h1><ol><li>省略常数项和常数系数</li><li>对于对数, 省略底数, 用 $log$ 表示</li></ol><h1 id="渐进符号"><a href="#渐进符号" class="headerlink" title="渐进符号"></a>渐进符号</h1><p>注意, 这里的函数均 <strong>渐进非负</strong> , 即 $f(n)$ 和 $g(n)$ 的值非负.</p><p>方便记忆的是, 大写符号为 <strong>非严格包含</strong> (含等于), 小写符号为 <strong>严格包含</strong> (不含等于)</p><p>注意的是小写渐进符号是 <strong>不一定</strong> 渐进紧确的, 也就是说 $\lim \limits_{n -&gt; \infty} \frac{T(n)}{f(n)}$ 可以为 $0(o)$ 或 $\infty(ω)$.</p><p>这里省去单独对小写渐进符号的描述.</p><h2 id="Θ-记号-渐进紧确界"><a href="#Θ-记号-渐进紧确界" class="headerlink" title="$Θ$ 记号 (渐进紧确界)"></a>$Θ$ 记号 (渐进紧确界)</h2><p>对于函数 $f(n)$ 和 $g(n)$ , $f(n)&#x3D;Θ(g(n))$ , 当且仅当 $\exists c_1, c_2,n_0&gt;0$,使得 $\forall n ≥ n_0,0≤ c_1·g(n) ≤ f(n) ≤ c_2 · g(n)$ .</p><p>也就是说, 如果函数 $f(n)&#x3D;Θ(g(n))$ ,那么我们能找到两个正数 $c_1,c_2$ 使得 $f(n)$ 被 $c_1·g(n)$ 和 $c_2·g(n)$ 夹在中间. 我们称 $g(n)$ 为 $f(n)$ 的 <strong>渐进紧确界</strong></p><h2 id="O-记号-渐进紧确上界"><a href="#O-记号-渐进紧确上界" class="headerlink" title="$O$ 记号 (渐进紧确上界)"></a>$O$ 记号 (渐进紧确上界)</h2><p>对于函数 $f(n)$ 和 $g(n)$,$f(n)&#x3D;O(g(n))$ ,当且仅当 $\exists c,n_0&gt;0$使得 $\forall n ≥ n_0,0 ≤ f(n) ≤ c · g(n)$.</p><p>也就是说,如果函数 $f(n)&#x3D;O(g(n))$,那么我们能找到一个正数 $c$ 使得 $f(n)$ 在 $c·g(n)$  下面. 我们称 $g(n)$ 为 $f(n)$ 的 <strong>渐进紧确上界</strong></p><h2 id="Ω-记号-渐进紧确下界"><a href="#Ω-记号-渐进紧确下界" class="headerlink" title="$Ω$ 记号 (渐进紧确下界)"></a>$Ω$ 记号 (渐进紧确下界)</h2><p>对于函数 $f(n)$ 和 $g(n)$, $f(n)&#x3D;Ω(g(n))$,当且仅当 $\exists c,n_0&gt;0$,使得 $\forall n ≥ n_0,0 ≤ c · g(n) ≤ f(n)$. </p><p>也就是说,如果函数 $f(n)&#x3D;Ω(g(n))$,那么我们能找到一个正数 $c$ 使得 $f(n)$ 在 $c·g(n)$  上面. 我们称 $g(n)$ 为 $f(n)$ 的 <strong>渐进紧确下界</strong></p><h1 id="主定理-M定理"><a href="#主定理-M定理" class="headerlink" title="主定理 (M定理)"></a>主定理 (M定理)</h1><p>主定理为用来计算递归时间复杂度的定理 $Master Theorem$</p><p>假设我们用递归递推式$$T(n) &#x3D; aT(\frac{n}{b})+f(n)$$</p><p>其中 $a$ 为递归子问题的数量,$\frac{n}{b}$ 为每个子问题的规模,$f(n)$ 为分解和合并的时间.</p><p> 那么就会有三种情况:</p><p><img data-src="/../images/Mtherom.jpg" alt="M"></p><ul><li>当 $f(n)$ 比 $n^{log_ba}$ 小时,$T(n) &#x3D; Θ(n^{log_ba})$</li><li>当 $f(n)$ 趋近于 $n^{log_ba}$ 时,$T(n) &#x3D; Θ(n^{log_ba}logn)$</li><li>当 $f(n)$ 比 $n^{log_ba}$ 大时,$T(n) &#x3D; Θ(f(n))$</li></ul><p>二分查找的时间复杂度:<br>$$T(n) &#x3D; T(\frac{n}{2}) + O(1) &#x3D; Θ(logn)$$</p><p>归并排序的时间复杂度:<br>$$T(n) &#x3D; 2T(\frac{n}{2}) + O(n) &#x3D; Θ(nlogn)$$</p><p>二叉树遍历的时间复杂度:<br>$$T(n) &#x3D; 2T(\frac{n}{2}) + O(1) &#x3D; Θ(n)$$</p><h1 id="时间复杂度类型"><a href="#时间复杂度类型" class="headerlink" title="时间复杂度类型"></a>时间复杂度类型</h1><p>通常情况下,我们所考虑的时间复杂度普遍指最坏时间复杂度,这也是最常用的时间复杂度,能够适用绝大多数情况.</p><p>但是对于一些特殊情况,我们并不能单单关注最坏时间复杂度.</p><h2 id="平均-期望-复杂度"><a href="#平均-期望-复杂度" class="headerlink" title="平均 (期望) 复杂度"></a>平均 (期望) 复杂度</h2><p>指的是输入数据 <strong>随机</strong> 的情况下期望的时间复杂度.</p><h2 id="均摊复杂度"><a href="#均摊复杂度" class="headerlink" title="均摊复杂度"></a>均摊复杂度</h2><p>在我们进行数据结构操作时,经常会对数据进行修改.因此一些看似单次复杂度高的算法,实际上所有操作均摊下来复杂度实际上并不高.因此我们并不能简单地分析最坏复杂度,而是需要均摊复杂度进行分析.</p><p>而均摊复杂度和平均(期望)复杂度的区别在于前者并不引入概率,是表示最坏情况下的所有操作的复杂度,而后者是指平均情况下的复杂度.</p><p>而计算均摊复杂度的算法就叫 <strong>摊还分析</strong>.</p><h3 id="摊还分析"><a href="#摊还分析" class="headerlink" title="摊还分析"></a>摊还分析</h3><h4 id="1-聚合法"><a href="#1-聚合法" class="headerlink" title="1.聚合法"></a>1.聚合法</h4><p>聚合分析,我们证明对所有的 $n$ ,单次最坏复杂度为 $T(n)$ ,则均摊复杂度为 $\frac{T(n)}{n}$</p><h5 id="例1-1-栈操作"><a href="#例1-1-栈操作" class="headerlink" title="例1.1:  栈操作"></a>例1.1:  栈操作</h5><p>我们假设一个栈的大小为 $k$ ,定义 <code>multipop(s)</code> 为弹出栈顶 $\min(s,k)$ 个元素.单次最坏情况显然为 $O(k)$ .但不可能每次操作都是最坏情况,事实上仅有进行 $n$ 次 <code>push</code> 操作后才能进行一次 $O(n)$ 的 <code>multipop</code>, 所以总均摊复杂度为 $O(n)$</p><h5 id="例1-2-二进制计数器递增"><a href="#例1-2-二进制计数器递增" class="headerlink" title="例1.2: 二进制计数器递增"></a>例1.2: 二进制计数器递增</h5><p>对于一个 $k$ 位初始位 0 的二进制数,我们使用 $INCREMENT$ 算法每次对这个二进制数加一.伪代码如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">i = 0</span><br><span class="line">   while i &lt; A.length and A[i] == 1</span><br><span class="line">       A[i] = 0</span><br><span class="line">       i = i+1</span><br><span class="line">   if i &lt; A.length</span><br><span class="line">       A[i] = 1</span><br></pre></td></tr></table></figure><p>显然对于连续 $k$ 个 1 的二进制数的单次操作复杂度为 $O(k)$ .但整体复杂度却不为 $O(nk)$ ,因为每一次不可能都为连续的 1, 事实上对于第 $i$ 位来说一共被操作 $\lfloor{\frac{n}{2^i}}\rfloor$ 次,所以总均摊复杂度为:</p><p>$$\sum \limits_{i&#x3D;0}^{k-1} \lfloor{\frac{n}{2^i}}\rfloor &lt; n\sum \limits_{i&#x3D;0}^{\infty} \lfloor{\frac{1}{2^i}}\rfloor &#x3D; 2n$$</p><p>因此总均摊复杂度为 $O(n)$</p><h4 id="核操作"><a href="#核操作" class="headerlink" title="核操作"></a>核操作</h4><p>我们对所有的操作赋予不同的费用,一些可能会大于或小于实际费用.这个费用我们称作 <strong>摊还代价</strong>.</p><p>当摊还代价大于实际代价时,我们将多出的差价称作信用存储起来.后续当摊还代价小于实际代价时,我们用存储的信用偿还.</p><h5 id="例2-1-栈操作"><a href="#例2-1-栈操作" class="headerlink" title="例2.1 栈操作"></a>例2.1 栈操作</h5><table><thead><tr><th>操作</th><th>实际费用</th><th>摊还代价</th></tr></thead><tbody><tr><td><code>push</code></td><td>1</td><td>2</td></tr><tr><td><code>pop</code></td><td>1</td><td>0</td></tr><tr><td><code>multipop</code></td><td>$\min(s,k)$</td><td>0</td></tr></tbody></table><p>在每次 <code>push</code> 中,我们能存入一点信用.而 <code>pop</code> 和 <code>multipop</code> 的次数显然不能超出栈中的元素数量,因此我们可以保证 <strong>任何时刻信用价值非负</strong></p><p>显然可以看出总均摊复杂度为 $O(n)$</p><h5 id="例2-2-二进制计数器递增"><a href="#例2-2-二进制计数器递增" class="headerlink" title="例2.2 二进制计数器递增"></a>例2.2 二进制计数器递增</h5><p>我们将 0 变为 1 的置位操作赋予 2 摊还代价,1 变为 0 的复位操作赋予 0 摊还代价.</p><p>由于每次会保证只有 1 次置位操作,而复位操作都可以用先前的信用偿还,因此可以保证 <strong>任何时候信用价值非负</strong></p><p>因此总均摊复杂度为 $O(n)$</p><h4 id="势能法"><a href="#势能法" class="headerlink" title="势能法"></a>势能法</h4><p>与核算法不同,势能法将预付代价描述为 <strong>势能</strong>, 释放势能可以支付未来的代价, 将势能与整个数据结构相联系而不是特定对象.</p><p>我们设第 $i$ 次操作的费用为 $c_i$ ,设第 $i$ 次操作后的数据状态为 $D_i$  ,初始状态为 $D_0$, 设摊还代价为 $c_i^{\prime}$ ,我们选取一个从数据结构的状态映射到势的函数 $F$ ,我们需要保证对于任意 $i$ , $F(D_i) \geq F(D_0)$ .</p><p>令 $c_i^{\prime} &#x3D; c_i + F(D[i]) - F(D[i-1])$ ,显然 $\sum \limits_{i&#x3D;1}^{n} c_i^{\prime} &#x3D; \sum \limits_{i&#x3D;1}^{n} c_i + F(D_n) - F(D_0)$ , 由于 $F(D_n) \geq F(D_0)$ ,所以 $\sum c_i^{\prime} \geq \sum c_i$ ,则 $\sum c_i^{\prime}$ 为总摊还复杂度的上界</p><h5 id="例3-1-栈操作"><a href="#例3-1-栈操作" class="headerlink" title="例3.1 栈操作"></a>例3.1 栈操作</h5><p>我们选取栈中元素个数为势能函数 $F$ .</p><p>对于 <code>push</code> 操作, 实际代价为 1, 势差为1, 摊还代价为2;</p><p>对于 <code>pop</code> 操作, 实际代价为1, 势差为-1, 摊还代价为0;</p><p>对于 <code>multipop</code> 操作, 实际代价为 $\min(s,k)$ ,势差同样为 $\min(s,k)$ ,摊还代价为0</p><p>因此总均摊复杂度为 $O(n)$</p><h5 id="例3-2-二进制计数器递增"><a href="#例3-2-二进制计数器递增" class="headerlink" title="例3.2 二进制计数器递增"></a>例3.2 二进制计数器递增</h5><p>我们设 1 的个数为势能函数 $F$</p><p>每次操作实际代价为 $k$, 势差为 $2-k$, 摊还代价为 $2$</p><p>则总摊还复杂度为 $O(n)$</p><hr><p>我们发现,以上三种摊还分析方法的本质其实是一样的,即 <strong>摊还</strong> 思想. 这种思想尤为重要,在以后的算法学习中,我们可以经常发现这种思想的身影.</p>]]></content:encoded>
      
      
      <category domain="http://nottogawabutsakiko.github.io/categories/%E7%AC%94%E8%AE%B0/">笔记</category>
      
      
      <category domain="http://nottogawabutsakiko.github.io/tags/%E7%AE%97%E6%B3%95/">算法</category>
      
      
      <comments>http://nottogawabutsakiko.github.io/%E7%AC%94%E8%AE%B0/complexity/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
